{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455ac03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa09bf",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a73795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/df_final_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602fd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['predicted_classes_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad12b80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>dateCreate</th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>source</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>review</th>\n",
       "      <th>predicted_classes_refined</th>\n",
       "      <th>final_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>992651</td>\n",
       "      <td>–Ω–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç —É—Å–ª–æ–≤–∏—è –∞–∫—Ü–∏–∏</td>\n",
       "      <td>–≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...</td>\n",
       "      <td>2025-08-29T23:30:38.746003Z</td>\n",
       "      <td>debitCards</td>\n",
       "      <td>–£–º–Ω–∞—è –∫–∞—Ä—Ç–∞ (–ü—Ä–µ–º–∏—É–º)</td>\n",
       "      <td>sravni</td>\n",
       "      <td>–≤ –∞–ø—Ä–µ–ª–µ –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫–∞—Ä—Ç—É ...</td>\n",
       "      <td>–Ω–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç —É—Å–ª–æ–≤–∏—è –∞–∫—Ü–∏–∏  –≤ –∞–ø—Ä–µ–ª–µ –≥–æ–¥–∞ —è —Ä–µ...</td>\n",
       "      <td>[1, 3, 14, 15]</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>998360</td>\n",
       "      <td>–∂–∞–ª–æ–±–∞ –Ω–∞ —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º</td>\n",
       "      <td>–∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...</td>\n",
       "      <td>2025-09-15T09:38:13.34818Z</td>\n",
       "      <td>debitCards</td>\n",
       "      <td>–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç</td>\n",
       "      <td>sravni</td>\n",
       "      <td>–∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ —Ü–µ–ª—å –±—ã–ª...</td>\n",
       "      <td>–∂–∞–ª–æ–±–∞ –Ω–∞ —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º  –∫—É–ø–∏–ª ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[debitCards]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>993744</td>\n",
       "      <td>–±–∞–Ω–∫ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Å–ª–æ–≤–∞ —Å–≤–æ–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –Ω–µ...</td>\n",
       "      <td>—Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...</td>\n",
       "      <td>2025-09-02T23:21:16.507166Z</td>\n",
       "      <td>debitCards</td>\n",
       "      <td>–£–º–Ω–∞—è –∫–∞—Ä—Ç–∞</td>\n",
       "      <td>sravni</td>\n",
       "      <td>—Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è –º–æ—ë –∫ –≥–∞–∑–ø—Ä–æ–º...</td>\n",
       "      <td>–±–∞–Ω–∫ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Å–ª–æ–≤–∞ —Å–≤–æ–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –Ω–µ...</td>\n",
       "      <td>[1, 6, 15]</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id                                              title  \\\n",
       "0      0  992651                        –Ω–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç —É—Å–ª–æ–≤–∏—è –∞–∫—Ü–∏–∏    \n",
       "1      1  998360            –∂–∞–ª–æ–±–∞ –Ω–∞ —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º    \n",
       "2      2  993744  –±–∞–Ω–∫ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Å–ª–æ–≤–∞ —Å–≤–æ–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –Ω–µ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  –≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...   \n",
       "1  –∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...   \n",
       "2  —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...   \n",
       "\n",
       "                    dateCreate     product            sub_product  source  \\\n",
       "0  2025-08-29T23:30:38.746003Z  debitCards  –£–º–Ω–∞—è –∫–∞—Ä—Ç–∞ (–ü—Ä–µ–º–∏—É–º)  sravni   \n",
       "1   2025-09-15T09:38:13.34818Z  debitCards            –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç  sravni   \n",
       "2  2025-09-02T23:21:16.507166Z  debitCards            –£–º–Ω–∞—è –∫–∞—Ä—Ç–∞  sravni   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  –≤ –∞–ø—Ä–µ–ª–µ –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫–∞—Ä—Ç—É ...   \n",
       "1  –∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ —Ü–µ–ª—å –±—ã–ª...   \n",
       "2  —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è –º–æ—ë –∫ –≥–∞–∑–ø—Ä–æ–º...   \n",
       "\n",
       "                                              review  \\\n",
       "0  –Ω–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç —É—Å–ª–æ–≤–∏—è –∞–∫—Ü–∏–∏  –≤ –∞–ø—Ä–µ–ª–µ –≥–æ–¥–∞ —è —Ä–µ...   \n",
       "1  –∂–∞–ª–æ–±–∞ –Ω–∞ —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º  –∫—É–ø–∏–ª ...   \n",
       "2  –±–∞–Ω–∫ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Å–ª–æ–≤–∞ —Å–≤–æ–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –Ω–µ...   \n",
       "\n",
       "  predicted_classes_refined                                      final_classes  \n",
       "0            [1, 3, 14, 15]  [debitCards, cashbackPromo, notifications, ref...  \n",
       "1                        []                                       [debitCards]  \n",
       "2                [1, 6, 15]  [debitCards, cashbackPromo, earlyRepayment, re...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1652c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['index', 'text', 'final_classes']].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c071a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: 23\n",
      "–ü—Ä–∏–º–µ—Ä—ã –º–µ—Ç–æ–∫: ['Salary&PremiumCards' 'autocredits' 'cardAccess' 'cashbackPromo'\n",
      " 'creditCards' 'creditCardsService' 'credits' 'currencyExchange'\n",
      " 'debitCards' 'depositAccess' 'deposits' 'earlyRepayment' 'loanIssues'\n",
      " 'mortgage' 'mortgageIssues' 'notifications' 'other' 'refinancing'\n",
      " 'remoteService' 'restructing' 'savings' 'serviceLevel'\n",
      " 'transactionErrors']\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['final_classes'])\n",
    "\n",
    "df['labels'] = y.tolist()\n",
    "\n",
    "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤:\", len(mlb.classes_))\n",
    "print(\"–ü—Ä–∏–º–µ—Ä—ã –º–µ—Ç–æ–∫:\", mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215ec15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'], df['labels'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_df = pd.DataFrame({'text': train_texts, 'labels': train_labels})\n",
    "test_df = pd.DataFrame({'text': test_texts, 'labels': test_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83141580",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e7cb4",
   "metadata": {},
   "source": [
    "## Classic Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a57ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#MODEL_NAME = \"DeepPavlov/rubert-base-cased\"\n",
    "# MODEL_NAME = \"DeepPavlov/rubert-base\"\n",
    "MODEL_NAME = \"ai-forever/ruBert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7a56d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341ae06d9ee44b83aa19506360ce5b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8379df9831147cba8459ee2e6758fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"__index_level_0__\"]) if \"__index_level_0__\" in train_dataset.column_names else train_dataset.remove_columns([\"text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"__index_level_0__\"]) if \"__index_level_0__\" in test_dataset.column_names else test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e63a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f9a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = (torch.sigmoid(torch.tensor(logits)) > 0.5).int().numpy()\n",
    "    labels = labels\n",
    "    return {\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53375cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d3dc783f2f4277afaeb5f2ae98200e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fc349d4a3e4d21a74fc5481e3603f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cast_labels_to_float(example):\n",
    "    example[\"labels\"] = [float(x) for x in example[\"labels\"]]\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(cast_labels_to_float)\n",
    "test_dataset = test_dataset.map(cast_labels_to_float)\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"../classifier_results\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='../logs',\n",
    "#     logging_steps=50,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"f1_micro\",\n",
    "#     save_total_limit=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369ba953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../classifier_results\",\n",
    "    evaluation_strategy=\"epoch\",       # –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑ –≤ —ç–ø–æ—Ö—É\n",
    "    save_strategy=\"epoch\",             # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Ä–∞–∑ –≤ —ç–ø–æ—Ö—É\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,               # –º–∞–∫—Å–∏–º—É–º 10 —ç–ø–æ—Ö\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='../logs',\n",
    "    logging_strategy=\"epoch\",          # –ª–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑ –≤ —ç–ø–æ—Ö—É\n",
    "    load_best_model_at_end=True,       # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "    metric_for_best_model=\"f1_micro\",  # –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "# callback –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=1)  \n",
    "# patience=1 ‚Üí –µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —ç–ø–æ—Ö–∞ –Ω–µ —É–ª—É—á—à–∏–ª–∞ –º–µ—Ç—Ä–∏–∫—É, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ed6166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8167b6d69f874e70b67b554284b949ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_307491/492247788.py:1: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  train_dataset = train_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd20a47d7074ff9a8665b5ffad7b63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_307491/492247788.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  test_dataset  = test_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n",
    "test_dataset  = test_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n",
    "\n",
    "# –£–±–∏—Ä–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ labels (—á—Ç–æ–±—ã Trainer –Ω–µ —Ç—Ä–æ–≥–∞–ª –∏—Ö)\n",
    "train_dataset = train_dataset.remove_columns(\"labels\")\n",
    "test_dataset  = test_dataset.remove_columns(\"labels\")\n",
    "\n",
    "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º float –∫–æ–ª–æ–Ω–∫—É –≤ labels\n",
    "train_dataset = train_dataset.rename_column(\"labels_float\", \"labels\")\n",
    "test_dataset  = test_dataset.rename_column(\"labels_float\", \"labels\")\n",
    "\n",
    "# –¢–µ–ø–µ—Ä—å set_format\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7080ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ GPU\n",
    "print(torch.cuda.is_available())  # True, –µ—Å–ª–∏ GPU –¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "print(torch.cuda.device_count())  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU\n",
    "print(torch.cuda.get_device_name(0))  # –∏–º—è –ø–µ—Ä–≤–æ–≥–æ GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46f435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20144' max='20144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20144/20144 44:48, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.726126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.108131</td>\n",
       "      <td>0.769384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.106506</td>\n",
       "      <td>0.777725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.105078</td>\n",
       "      <td>0.781371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20144, training_loss=0.10831447325593617, metrics={'train_runtime': 2689.3523, 'train_samples_per_second': 59.918, 'train_steps_per_second': 7.49, 'total_flos': 2.120285478614016e+16, 'train_loss': 0.10831447325593617, 'epoch': 4.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5876f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç ---\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Salary&PremiumCards       0.79      0.73      0.76       892\n",
      "        autocredits       0.78      0.68      0.72       788\n",
      "         cardAccess       0.80      0.79      0.80       900\n",
      "      cashbackPromo       0.83      0.91      0.87      1064\n",
      "        creditCards       0.78      0.68      0.73      1669\n",
      " creditCardsService       0.79      0.72      0.75       856\n",
      "            credits       0.79      0.71      0.75       814\n",
      "   currencyExchange       0.77      0.44      0.56       557\n",
      "         debitCards       0.86      0.87      0.87      5686\n",
      "      depositAccess       0.79      0.65      0.71       626\n",
      "           deposits       0.75      0.76      0.75       715\n",
      "     earlyRepayment       0.83      0.83      0.83       906\n",
      "         loanIssues       0.82      0.71      0.76       688\n",
      "           mortgage       0.79      0.80      0.79       674\n",
      "     mortgageIssues       0.84      0.85      0.84       787\n",
      "      notifications       0.78      0.71      0.74       826\n",
      "              other       0.00      0.00      0.00        97\n",
      "        refinancing       0.75      0.74      0.75       686\n",
      "      remoteService       0.72      0.68      0.70       799\n",
      "        restructing       0.60      0.41      0.48       217\n",
      "            savings       0.70      0.55      0.61       563\n",
      "       serviceLevel       0.67      0.01      0.03       146\n",
      "  transactionErrors       0.82      0.77      0.79       735\n",
      "\n",
      "          micro avg       0.81      0.76      0.78     21691\n",
      "          macro avg       0.74      0.65      0.68     21691\n",
      "       weighted avg       0.80      0.76      0.77     21691\n",
      "        samples avg       0.77      0.75      0.75     21691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "preds = (torch.sigmoid(torch.tensor(predictions.predictions)) > 0.5).int().numpy()\n",
    "\n",
    "print(\"\\n--- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç ---\\n\")\n",
    "print(classification_report(test_labels.tolist(), preds, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa945f",
   "metadata": {},
   "source": [
    "## Final Model (Full Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bda2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>final_classes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...</td>\n",
       "      <td>[debitCards]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>—Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>–≤ –∏—é–Ω–µ 2025 –≥–æ–¥–∞ —è –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –ø—Ä–µ–º–∏–∞–ª—å–Ω—É—é ...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>–¥–æ–±—Ä—ã–π –¥–µ–Ω—å –≤ —Å–≤—è–∑–∏ —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –Ω–∞ –Ω–æ–≤—É—é —Ä–∞–±...</td>\n",
       "      <td>[debitCards, depositAccess, remoteService]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50352</th>\n",
       "      <td>50352</td>\n",
       "      <td>–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ —Ç—É—Ç –∑–∞–º–∞–Ω–∏–≤–∞–ª –∫—Ä–µ–¥–∏—Ç–æ–º –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–º ...</td>\n",
       "      <td>[other, earlyRepayment, loanIssues]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50353</th>\n",
       "      <td>50353</td>\n",
       "      <td>—Å–∏—Ç—É–∞—Ü–∏—è –¥–æ–≤–æ–ª—å–Ω–æ —Å—Ç—Ä–∞–Ω–Ω–∞—è –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50354</th>\n",
       "      <td>50354</td>\n",
       "      <td>–≤ –±–∞–Ω–∫–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –≤—Å–µ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>50355</td>\n",
       "      <td>–æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–∞–∫—Ç —Ü–µ–Ω—Ç—Ä 10 –±–∞–ª–ª–æ–≤ –∞ –≤–æ—Ç —Ä–∞–±–æ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50356</th>\n",
       "      <td>50356</td>\n",
       "      <td>–æ—Ç–∫—Ä—ã–≤–∞–ª–∞ —Å—á–µ—Ç —Å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–º –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –ø—Ä–æ—Ü–µ–Ω...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50357 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  \\\n",
       "0          0  –≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...   \n",
       "1          1  –∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...   \n",
       "2          2  —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...   \n",
       "3          3  –≤ –∏—é–Ω–µ 2025 –≥–æ–¥–∞ —è –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –ø—Ä–µ–º–∏–∞–ª—å–Ω—É—é ...   \n",
       "4          4  –¥–æ–±—Ä—ã–π –¥–µ–Ω—å –≤ —Å–≤—è–∑–∏ —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –Ω–∞ –Ω–æ–≤—É—é —Ä–∞–±...   \n",
       "...      ...                                                ...   \n",
       "50352  50352  –≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ —Ç—É—Ç –∑–∞–º–∞–Ω–∏–≤–∞–ª –∫—Ä–µ–¥–∏—Ç–æ–º –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–º ...   \n",
       "50353  50353  —Å–∏—Ç—É–∞—Ü–∏—è –¥–æ–≤–æ–ª—å–Ω–æ —Å—Ç—Ä–∞–Ω–Ω–∞—è –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ...   \n",
       "50354  50354  –≤ –±–∞–Ω–∫–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –≤—Å–µ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ...   \n",
       "50355  50355  –æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–∞–∫—Ç —Ü–µ–Ω—Ç—Ä 10 –±–∞–ª–ª–æ–≤ –∞ –≤–æ—Ç —Ä–∞–±–æ...   \n",
       "50356  50356  –æ—Ç–∫—Ä—ã–≤–∞–ª–∞ —Å—á–µ—Ç —Å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–º –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –ø—Ä–æ—Ü–µ–Ω...   \n",
       "\n",
       "                                           final_classes  \\\n",
       "0      [debitCards, cashbackPromo, notifications, ref...   \n",
       "1                                           [debitCards]   \n",
       "2      [debitCards, cashbackPromo, earlyRepayment, re...   \n",
       "3      [debitCards, cashbackPromo, notifications, ref...   \n",
       "4             [debitCards, depositAccess, remoteService]   \n",
       "...                                                  ...   \n",
       "50352                [other, earlyRepayment, loanIssues]   \n",
       "50353                                            [other]   \n",
       "50354                                            [other]   \n",
       "50355                                            [other]   \n",
       "50356                                            [other]   \n",
       "\n",
       "                                                  labels  \n",
       "0      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "50352  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "50353  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50354  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50355  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50356  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[50357 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d67fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ff92c3088841b5843bb8917c5851d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c8f97eb2904867b0e0ba15e2908907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "dataset = dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n",
    "dataset = dataset.remove_columns(\"labels\")\n",
    "dataset = dataset.rename_column(\"labels_float\", \"labels\")\n",
    "dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2193accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6567dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../classifier_full_model\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,           # —Ç–æ–ª—å–∫–æ 4 —ç–ø–æ—Ö–∏\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='../logs_full',\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,  # –±–µ–∑ early stopping\n",
    "    save_total_limit=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b6409d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25180' max='25180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25180/25180 57:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6295</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12590</td>\n",
       "      <td>0.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18885</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25180</td>\n",
       "      <td>0.056900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25180, training_loss=0.07849992141541837, metrics={'train_runtime': 3477.2388, 'train_samples_per_second': 57.928, 'train_steps_per_second': 7.241, 'total_flos': 2.650396322367283e+16, 'train_loss': 0.07849992141541837, 'epoch': 4.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# –æ–±—É—á–µ–Ω–∏–µ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f8109cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../classifier_full_model/tokenizer_config.json',\n",
       " '../classifier_full_model/special_tokens_map.json',\n",
       " '../classifier_full_model/vocab.txt',\n",
       " '../classifier_full_model/added_tokens.json',\n",
       " '../classifier_full_model/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../classifier_full_model\")\n",
    "tokenizer.save_pretrained(\"../classifier_full_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0da5b9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>final_classes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...</td>\n",
       "      <td>[debitCards]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>—Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–≤ –∏—é–Ω–µ 2025 –≥–æ–¥–∞ —è –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –ø—Ä–µ–º–∏–∞–ª—å–Ω—É—é ...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–¥–æ–±—Ä—ã–π –¥–µ–Ω—å –≤ —Å–≤—è–∑–∏ —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –Ω–∞ –Ω–æ–≤—É—é —Ä–∞–±...</td>\n",
       "      <td>[debitCards, depositAccess, remoteService]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50352</th>\n",
       "      <td>–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ —Ç—É—Ç –∑–∞–º–∞–Ω–∏–≤–∞–ª –∫—Ä–µ–¥–∏—Ç–æ–º –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–º ...</td>\n",
       "      <td>[other, earlyRepayment, loanIssues]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50353</th>\n",
       "      <td>—Å–∏—Ç—É–∞—Ü–∏—è –¥–æ–≤–æ–ª—å–Ω–æ —Å—Ç—Ä–∞–Ω–Ω–∞—è –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50354</th>\n",
       "      <td>–≤ –±–∞–Ω–∫–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –≤—Å–µ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>–æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–∞–∫—Ç —Ü–µ–Ω—Ç—Ä 10 –±–∞–ª–ª–æ–≤ –∞ –≤–æ—Ç —Ä–∞–±–æ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50356</th>\n",
       "      <td>–æ—Ç–∫—Ä—ã–≤–∞–ª–∞ —Å—á–µ—Ç —Å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–º –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –ø—Ä–æ—Ü–µ–Ω...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50357 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      –≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...   \n",
       "1      –∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...   \n",
       "2      —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...   \n",
       "3      –≤ –∏—é–Ω–µ 2025 –≥–æ–¥–∞ —è –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –ø—Ä–µ–º–∏–∞–ª—å–Ω—É—é ...   \n",
       "4      –¥–æ–±—Ä—ã–π –¥–µ–Ω—å –≤ —Å–≤—è–∑–∏ —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –Ω–∞ –Ω–æ–≤—É—é —Ä–∞–±...   \n",
       "...                                                  ...   \n",
       "50352  –≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ —Ç—É—Ç –∑–∞–º–∞–Ω–∏–≤–∞–ª –∫—Ä–µ–¥–∏—Ç–æ–º –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–º ...   \n",
       "50353  —Å–∏—Ç—É–∞—Ü–∏—è –¥–æ–≤–æ–ª—å–Ω–æ —Å—Ç—Ä–∞–Ω–Ω–∞—è –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ...   \n",
       "50354  –≤ –±–∞–Ω–∫–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –≤—Å–µ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ...   \n",
       "50355  –æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–∞–∫—Ç —Ü–µ–Ω—Ç—Ä 10 –±–∞–ª–ª–æ–≤ –∞ –≤–æ—Ç —Ä–∞–±–æ...   \n",
       "50356  –æ—Ç–∫—Ä—ã–≤–∞–ª–∞ —Å—á–µ—Ç —Å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–º –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –ø—Ä–æ—Ü–µ–Ω...   \n",
       "\n",
       "                                           final_classes  \\\n",
       "0      [debitCards, cashbackPromo, notifications, ref...   \n",
       "1                                           [debitCards]   \n",
       "2      [debitCards, cashbackPromo, earlyRepayment, re...   \n",
       "3      [debitCards, cashbackPromo, notifications, ref...   \n",
       "4             [debitCards, depositAccess, remoteService]   \n",
       "...                                                  ...   \n",
       "50352                [other, earlyRepayment, loanIssues]   \n",
       "50353                                            [other]   \n",
       "50354                                            [other]   \n",
       "50355                                            [other]   \n",
       "50356                                            [other]   \n",
       "\n",
       "                                                  labels  \n",
       "0      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "50352  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "50353  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50354  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50355  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50356  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[50357 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d2e80",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfd8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../classifier_full_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67724d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "model.eval()\n",
    "\n",
    "# –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bd6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(texts, threshold=0.5):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]  # –µ—Å–ª–∏ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    # –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥—É\n",
    "    preds = (probs > threshold).astype(int)\n",
    "\n",
    "    # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏–º–µ–Ω–∞ –º–µ—Ç–æ–∫\n",
    "    predicted_labels = [mlb.inverse_transform([p])[0] for p in preds]\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2623ca1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Salary&PremiumCards', 'autocredits', 'cardAccess',\n",
       "       'cashbackPromo', 'creditCards', 'creditCardsService', 'credits',\n",
       "       'currencyExchange', 'debitCards', 'depositAccess', 'deposits',\n",
       "       'earlyRepayment', 'loanIssues', 'mortgage', 'mortgageIssues',\n",
       "       'notifications', 'other', 'refinancing', 'remoteService',\n",
       "       'restructing', 'savings', 'serviceLevel', 'transactionErrors'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32b12e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{MODEL_PATH}/final_mlb_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(mlb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b49ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{MODEL_PATH}/final_mlb_encoder.pkl', 'rb') as f:\n",
    "    mlb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1952f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>final_classes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...</td>\n",
       "      <td>[debitCards]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>—Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>–≤ –∏—é–Ω–µ 2025 –≥–æ–¥–∞ —è –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –ø—Ä–µ–º–∏–∞–ª—å–Ω—É—é ...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>–¥–æ–±—Ä—ã–π –¥–µ–Ω—å –≤ —Å–≤—è–∑–∏ —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –Ω–∞ –Ω–æ–≤—É—é —Ä–∞–±...</td>\n",
       "      <td>[debitCards, depositAccess, remoteService]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50352</th>\n",
       "      <td>50352</td>\n",
       "      <td>–≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ —Ç—É—Ç –∑–∞–º–∞–Ω–∏–≤–∞–ª –∫—Ä–µ–¥–∏—Ç–æ–º –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–º ...</td>\n",
       "      <td>[other, earlyRepayment, loanIssues]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50353</th>\n",
       "      <td>50353</td>\n",
       "      <td>—Å–∏—Ç—É–∞—Ü–∏—è –¥–æ–≤–æ–ª—å–Ω–æ —Å—Ç—Ä–∞–Ω–Ω–∞—è –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50354</th>\n",
       "      <td>50354</td>\n",
       "      <td>–≤ –±–∞–Ω–∫–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –≤—Å–µ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>50355</td>\n",
       "      <td>–æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–∞–∫—Ç —Ü–µ–Ω—Ç—Ä 10 –±–∞–ª–ª–æ–≤ –∞ –≤–æ—Ç —Ä–∞–±–æ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50356</th>\n",
       "      <td>50356</td>\n",
       "      <td>–æ—Ç–∫—Ä—ã–≤–∞–ª–∞ —Å—á–µ—Ç —Å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–º –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –ø—Ä–æ—Ü–µ–Ω...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50357 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  \\\n",
       "0          0  –≤ –∞–ø—Ä–µ–ª–µ 2025 –≥–æ–¥–∞ —è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –¥–µ–±–µ—Ç–æ–≤—É—é –∫...   \n",
       "1          1  –∫—É–ø–∏–ª —É—Å–ª—É–≥—É –≥–∞–∑–ø—Ä–æ–º –±–æ–Ω—É—Å –ø—Ä–µ–º–∏—É–º –∑–∞ 2 —Ü–µ–ª—å –±...   \n",
       "2          2  —Ö–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –∏—Å—Ç–æ—Ä–∏–µ–π –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–ª–∞ –º–æ—ë –¥–æ–≤...   \n",
       "3          3  –≤ –∏—é–Ω–µ 2025 –≥–æ–¥–∞ —è –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –ø—Ä–µ–º–∏–∞–ª—å–Ω—É—é ...   \n",
       "4          4  –¥–æ–±—Ä—ã–π –¥–µ–Ω—å –≤ —Å–≤—è–∑–∏ —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –Ω–∞ –Ω–æ–≤—É—é —Ä–∞–±...   \n",
       "...      ...                                                ...   \n",
       "50352  50352  –≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ —Ç—É—Ç –∑–∞–º–∞–Ω–∏–≤–∞–ª –∫—Ä–µ–¥–∏—Ç–æ–º –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–º ...   \n",
       "50353  50353  —Å–∏—Ç—É–∞—Ü–∏—è –¥–æ–≤–æ–ª—å–Ω–æ —Å—Ç—Ä–∞–Ω–Ω–∞—è –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ...   \n",
       "50354  50354  –≤ –±–∞–Ω–∫–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –≤—Å–µ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ...   \n",
       "50355  50355  –æ–±—Ä–∞—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–∞–∫—Ç —Ü–µ–Ω—Ç—Ä 10 –±–∞–ª–ª–æ–≤ –∞ –≤–æ—Ç —Ä–∞–±–æ...   \n",
       "50356  50356  –æ—Ç–∫—Ä—ã–≤–∞–ª–∞ —Å—á–µ—Ç —Å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–º –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –ø—Ä–æ—Ü–µ–Ω...   \n",
       "\n",
       "                                           final_classes  \\\n",
       "0      [debitCards, cashbackPromo, notifications, ref...   \n",
       "1                                           [debitCards]   \n",
       "2      [debitCards, cashbackPromo, earlyRepayment, re...   \n",
       "3      [debitCards, cashbackPromo, notifications, ref...   \n",
       "4             [debitCards, depositAccess, remoteService]   \n",
       "...                                                  ...   \n",
       "50352                [other, earlyRepayment, loanIssues]   \n",
       "50353                                            [other]   \n",
       "50354                                            [other]   \n",
       "50355                                            [other]   \n",
       "50356                                            [other]   \n",
       "\n",
       "                                                  labels  \n",
       "0      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "50352  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "50353  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50354  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50355  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50356  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[50357 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebfe3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(texts, threshold=0.5):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]  # –µ—Å–ª–∏ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    # –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥—É\n",
    "    preds = (probs > threshold).astype(int)\n",
    "    \n",
    "    # —Ç–µ–ø–µ—Ä—å preds —Ç–æ—á–Ω–æ numpy array —Å —Ñ–æ—Ä–º–æ–π (num_texts, num_labels)\n",
    "    predicted_labels = mlb.inverse_transform(preds)\n",
    "    \n",
    "    return list(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d543929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3]\n",
    "l.pop(0)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2ebd378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": [{\"id\": 0, \"text\": \"—è –±—Ä–∞–ª –∫—Ä–µ–¥–∏—Ç —É–∂–µ –≤—ã–ø–ª–∞—Ç–∏–ª –ø–æ–ª—å–∑—É—é—Å—å –∫–∞—Ä—Ç–∞–º–∏ –±–∞–Ω–∫–∞ —É –º–µ–Ω—è –Ω–µ—Ç –Ω–∏–∫–∞–∫–∏—Ö –Ω–∞—Ä–µ–∫–∞–Ω–∏–π –ø–æ –ø–æ–≤–æ–¥—É —Ä–∞–±–æ—Ç—ã –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –º–Ω–µ –æ—á–µ–Ω—å –Ω—Ä–∞–≤–∏—Ç—Å—è —Ä–∞–±–æ—Ç–∞ –±–∞–Ω–∫–∞ —Ö–æ—á–µ—Ç—Å—è –ø–æ–∂–µ–ª–∞—Ç—å –≤—Å–µ–º —Ä–∞–±–æ—Ç–Ω–∏–∫–∞–º –≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∏ —É—Å–ø–µ—Ö–æ–≤ \"}, {\"id\": 1, \"text\": \"–Ω–µ–¥–∞–≤–Ω–æ –æ–±—Ä–∞—Ç–∏–ª—Å—è –≤ –≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ –∏ –±—ã–ª —É–∂–∞—Å–Ω–æ —É–¥–∏–≤–ª—ë–Ω —Ä–∞–∑–≥–∏–ª—å–¥—è–π—Å–∫–∏–º –æ—Ç–Ω–æ—à–µ–Ω–∏–µ–º –±–∞–Ω–∫–∞ –∫ –∫–ª–∏–µ–Ω—Ç—É br 22 07 –æ—Å—Ç–∞–≤–∏–ª –∑–∞—è–≤–∫—É –Ω–∞ –∫—Ä–µ–¥–∏—Ç–Ω—É—é –∫–∞—Ä—Ç—É –±–∞–Ω–∫ –æ–¥–æ–±—Ä–∏–ª –∑–∞—è–≤–∫—É –Ω–∞ –∫—Ä–µ–¥–∏—Ç–Ω—É—é –∫–∞—Ä—Ç—É –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å —Å–æ –º–Ω–æ–π —Å–≤—è–∑–∞–ª—Å—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –±–∞–Ω–∫–∞ —Å –∫–æ—Ç–æ—Ä—ã–º –º—ã –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª–∏ –≤—Ä–µ–º—è –¥–ª—è –ø—Ä–∏–µ–∑–¥–∞ –∫—É—Ä—å–µ—Ä–∞ 24 07 –∫–æ –º–Ω–µ –ø—Ä–∏–µ—Ö–∞–ª –∫—É—Ä—å–µ—Ä –¥–ª—è –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è –¥–æ–≥–æ–≤–æ—Ä–∞ –Ω–∞ –∫—Ä–µ–¥–∏—Ç–Ω—É—é –∫–∞—Ä—Ç—É –Ω–æ –∫—Ç–æ —Ç–æ –≤ –æ—Ñ–∏—Å–µ –ø–µ—Ä–µ–ø—É—Ç–∞–ª –≤–ª–æ–∂–µ–Ω–∏—è –∏ –≤ –∫–æ–Ω–≤–µ—Ä—Ç–µ —Å –º–æ–∏–º –∏–º–µ–Ω–µ–º –æ–∫–∞–∑–∞–ª—Å—è –¥–æ–≥–æ–≤–æ—Ä –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –¥—Ä—É–≥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –º—ã —Å –∫—É—Ä—å–µ—Ä–æ–º –¥–æ–≥–æ–≤–æ—Ä–∏–ª–∏—Å—å —á—Ç–æ –æ–Ω –ø—Ä–∏–≤–µ–∑—ë—Ç –º–æ–π –¥–æ–≥–æ–≤–æ—Ä —á–µ—Ä–µ–∑ –¥–µ–Ω—å —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª–∏ –≤—Ä–µ–º—è –∏ —Å–ø–æ–∫–æ–π–Ω–æ –ø–æ–ø—Ä–æ—â–∞–ª–∏—Å—å –∫–∞–∫ –≤–µ—á–µ—Ä–æ–º —ç—Ç–æ–≥–æ –∂–µ –¥–Ω—è –º–Ω–µ –ø–æ—Å—Ç—É–ø–∞–µ—Ç —Å–º—Å –æ—Ç –≥–∞–∑–ø—Ä–æ–º –±–∞–Ω–∫–∞ —á—Ç–æ –ø–æ –º–æ–µ–π –∑–∞—è–≤–∫–µ –ø—Ä–∏–Ω—è—Ç–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å–∫–∞–∑–∞—Ç—å —á—Ç–æ —è —É–¥–∏–≤–∏–ª—Å—è –Ω–∏—á–µ–≥–æ –Ω–µ —Å–∫–∞–∑–∞—Ç—å —è —Ç—É—Ç –∂–µ –ø–æ–∑–≤–æ–Ω–∏–ª –Ω–∞ –≥–æ—Ä—è—á—É—é –ª–∏–Ω–∏—é –≥–¥–µ –º–Ω–µ —Å–∫–∞–∑–∞–ª–∏ —á—Ç–æ —ç—Ç–æ –±—ã–ª–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–¥–æ–±—Ä–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ —á—Ç–æ —è –æ—Ç–≤–µ—Ç–∏–ª —á—Ç–æ –º–Ω–µ –ø—Ä–∏—à–ª–∞ —Å–º—Å –æ —Ç–æ–º —á—Ç–æ –º–Ω–µ –æ–¥–æ–±—Ä–µ–Ω–∞ –∫–∞—Ä—Ç–∞ —Å –ª–∏–º–∏—Ç–æ–º –∞ —Ç–∞–∫–∂–µ –µ—Å–ª–∏ –±—ã –≤ –æ—Ñ–∏—Å–µ –∫—Ç–æ —Ç–æ –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞–ª –∫–æ–Ω–≤–µ—Ä—Ç—ã —Ç–æ —è –±—ã –ø–æ–¥–ø–∏—Å–∞–ª —Å –±–∞–Ω–∫–æ–º –¥–æ–≥–æ–≤–æ—Ä –Ω–∞ –∫—Ä–µ–¥–∏—Ç–Ω—É—é –∫–∞—Ä—Ç—É —Ç—É—Ç –æ–ø–µ—Ä–∞—Ç–æ—Ä –Ω–∞—á–∞–ª–∞ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ —Ç–æ–º —á—Ç–æ –±–∞–Ω–∫ –º–æ–≥ –≤—Å–µ —Ä–∞–≤–Ω–æ –º–æ–≥ –±—ã –æ—Ç–∫–∞–∑–∞—Ç—å –º–Ω–µ –≤ –∫—Ä–µ–¥–∏—Ç–Ω–æ–π –∫–∞—Ä—Ç–µ –Ω–∞ –º–æ–π –≤–æ–ø—Ä–æ—Å –∫–∞–∫ –±—ã –±–∞–Ω–∫ —Å–º–æ–≥ –±—ã —Ä–∞–∑–æ—Ä–≤–∞—Ç—å –∫—Ä–µ–¥–∏—Ç–Ω—ã–π –¥–æ–≥–æ–≤–æ—Ä —Å–ø—É—Å—Ç—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞—Å–æ–≤ –ø–æ—Å–ª–µ –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–µ —Å–º–æ–≥–ª–∞ br –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∏–ª–∏ –Ω–µ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –≤ —ç—Ç–æ—Ç –±–∞–Ω–∫ –∑–∞ –∫—Ä–µ–¥–∏—Ç–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏ –¥—É–º–∞–π—Ç–µ —Å–∞–º–∏ \"}, {\"id\": 2, \"text\": \"–æ–¥–æ–ª–∂–∏–ª –Ω–∞ —Ç—Ä–∏ –¥–Ω—è –∏ –≤–µ—Ä–Ω—É–ª –∞ —Å–ø—É—Å—Ç—è –ø–∞—Ä—É –¥–Ω–µ–π —Å–ø–∏—Å–∞–ª–∏ –µ—â—ë —ç—Ç–æ —á—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —á—Ç–æ –ª–∏ –≥–∏–≥–∞–Ω—Ç—Å–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ª–æ–≤–∏—è –Ω–∞ —Å—Ç–æ–ª—å–∫–æ –Ω–µ –ø–æ–Ω—è—Ç–Ω–æ –Ω–∞–ø–∏—Å–∞–Ω–æ —á—Ç–æ –ø–æ–∫–∞ —Ä–∞–∑–±–µ—Ä—ë—à—å—Å—è –∫–æ—Ä–æ—á–µ –æ—Ç–∫–∞–∑—ã–≤–∞—é—Å—å –æ—Ç —Ç–∞–∫–∏—Ö —É—Å–ª—É–≥ –∏ –≤—Å–µ–º –æ—á–µ–Ω—å –Ω–µ —Å–æ–≤–µ—Ç—É—é —Å–≤—è–∑—ã–≤–∞—Ç—å—Å—è —Å –ø–æ–¥–æ–±–Ω—ã–º –∫–∞—á–∞—é—Ç –≥–∞–∑ –∏–∑ –Ω–µ–¥—Ä –Ω–∞—à–µ–π –æ–±—â–µ–π –∑–µ–º–ª–∏ –ø—Ä–æ–¥–∞—é—Ç –¥–∞ –µ—â—ë –∏ –ª—é–¥–µ–π –æ–±–º–∞–Ω—ã–≤–∞—é—Ç \"}, {\"id\": 3, \"text\": \"–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –±–∞–Ω–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ —Å—á–µ—Ç—É —Ç–µ—Ö–æ—Ç–¥–µ–ª —Ü–µ–ª—ã–π –º–µ—Å—è—Ü –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è –∫–æ–Ω—Å—Ç–∞—Ç–∞—Ü–∏–µ–π —ç—Ç–æ–≥–æ —Ñ–∞–∫—Ç–∞ –∑–≤–æ–Ω–∫–∞–º–∏ –Ω–∞ –º–æ–±–∏–ª—É –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–≤–æ–Ω–æ–∫ —Å–∫–∞–∑–∞–ª–∏ –≤–∞–º –∫–æ–ª–ª —Ü–µ–Ω—Ç—Ä –ø–æ—Å—á–∏—Ç–∞–µ—Ç –Ω–∞—á–∏—Å–ª–µ–Ω–Ω—ã–µ –¥–µ–Ω—å–≥–∏ –ø–æ —Å—á–µ—Ç—É –∑–≤–æ–Ω—é –≤ –∫–æ–ª–ª —Ü–µ–Ω—Ç—Ä —Ç–∞–º –≥–æ–≤–æ—Ä—è—Ç –º—ã –Ω–µ –∑–Ω–∞–µ–º –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è —Ä–∞—Å—á–µ—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç–µ –≤ –æ—Ñ–∏—Å –¥–≤–∞ –≥–æ–¥–∞ –Ω–∞–∑–∞–¥ –ø–æ–ø—Ä–æ—Å–∏–ª —á—Ç–æ–±—ã –ø–æ–∫–∞–∑—ã–≤–∞–ª–∏ –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–æ –∏ –Ω–æ–º–µ—Ä —Å—á–µ—Ç–∞ –∫—É–¥–∞ —É—Ö–æ–¥—è—Ç –¥–µ–Ω—å–≥–∏ –∑–∞ –∂–∫—Ö —Ç–∞–∫ –∏ –Ω–µ –¥–µ–ª–∞–ª–∏ \"}, {\"id\": 4, \"text\": \"14 03 2023 —É –º–µ–Ω—è –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–º—É—â–µ—Å—Ç–≤–∞ –∏ —è –±—ã–ª–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞ –æ—Ç –¥–æ–ª–≥–æ–≤ –ø–æ —Ä–µ—à–µ–Ω–∏—é –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–æ–≥–æ —Å—É–¥–∞ –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏—è —á–∞—Å—Ç—å –±–∞–Ω–∫–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–∫—Ä—ã–ª–∏ –¥–æ–ª–≥–∏ –≤ —á–∞—Å—Ç—å —è –æ—Ç–Ω–µ—Å–ª–∞ —Ä–µ—à–µ–Ω–∏–µ —Å—É–¥–∞ –æ–¥–Ω–∞–∫–æ –≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ –¥–æ–ª–≥ –∑–∞–∫—Ä—ã–≤–∞—Ç—å –Ω–µ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ —è 13 07 2023 –ø—Ä–∏—à–ª–∞ –≤ –æ—Ç–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∞–¥—Ä–µ—Å—É —Ö–∏–º–∫–∏–Ω—Å–∫–∏–π –±—É–ª—å–≤–∞—Ä –¥ 23 —É –º–µ–Ω—è –æ—Ç–∫–∞–∑–∞–ª–∏—Å—å –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ —Å—É–¥–∞ –∏ –∫—É–¥–∞ –ª–∏–±–æ –µ–≥–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–∫–∞–∑–∞–ª–∏ –µ—Ö–∞—Ç—å –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –æ—Ñ–∏—Å –≤ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—é —Ö–æ—Ç—è –Ω–∞ –≥–æ—Ä—è—á–µ–π –ª–∏–Ω–∏–∏ —Å–∫–∞–∑–∞–ª–∏ –ø–æ—Ç–æ–º —á—Ç–æ –ø–æ—Å–µ—â–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –æ—Ñ–∏—Å–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏ —Å–∞–º–æ–µ –≥–ª–∞–≤–Ω–æ–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –æ—Ç–¥–µ–ª–µ–Ω–∏—è –∑–∞–¥–∞–ª–∞ –º–Ω–µ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∫–æ–≥–¥–∞ —Å–æ–±–∏—Ä–∞–µ—Ç–µ—Å—å –æ–ø–ª–∞—á–∏–≤–∞—Ç—å –¥–æ–ª–≥ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –ø–æ –∫—Ä–µ–¥–∏—Ç–Ω–æ–π –∫–∞—Ä—Ç–µ —Ç–µ–º —Å–∞–º—ã–º —Å—á–∏—Ç–∞–π –ø–æ—Ç—Ä–µ–±–æ–≤–∞–≤ —É –º–µ–Ω—è –ø–æ–≥–∞—Å–∏—Ç—å –¥–æ–ª–≥ –∑–Ω–∞—è —á—Ç–æ —è —è–≤–ª—è—é—Å—å –±–∞–Ω–∫—Ä–æ—Ç–æ–º –∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞ –æ—Ç –¥–æ–ª–≥–∞ –∫–æ–≥–¥–∞ –ø–æ—Å–ª–µ –≤—Å–µ–≥–æ —ç—Ç–æ–≥–æ —è —Å–æ–∑–≤–æ–Ω–∏–ª–∞—Å—å —Å —é—Ä–∏—Å—Ç–æ–º —á—Ç–æ–±—ã —É—Ç–æ—á–Ω–∏—Ç—å —É –Ω–µ–≥–æ —á—Ç–æ –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –¥–µ–ª–∞—Ç—å –æ–Ω–∞ —Å–∏–¥–µ–ª–∞ –∏ —Ö–∏—Ö–∏–∫–∞–ª–∞ —Å–æ —Å–≤–æ–µ–π –∫–æ–ª–ª–µ–≥–æ–π —Å–º–æ—Ç—Ä—è –Ω–∞ –º–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä —á—Ç–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å–µ–±–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –∏ –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —Å–ø–∏—Å–∞–Ω –º–æ–π –¥–æ–ª–≥ \"}, {\"id\": 5, \"text\": \"—Å –±–∞–Ω–∫–æ–º –∑–Ω–∞–∫–æ–º –¥–∞–≤–Ω–æ –±—ã–ª–æ –≤—Å–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–æ –∞–≤–≥—É—Å—Ç–∞ 2022 –≥–æ–¥ –≤ –∞–≤–≥—É—Å—Ç–µ –ø–æ—à–µ–ª –≤ –æ—Ç–ø—É—Å–∫ –∏ —Ä–µ—à–∏–ª –ø–æ–ª–æ–∂–∏—Ç—å –Ω–∞ –∫—Ä–µ–¥–∏—Ç –∑–∞ –¥–≤–∞ –º–µ—Å—è—Ü–∞ –∑–∞ –∞–≤–≥—É—Å—Ç –≤—ã—á–ª–∏ –Ω–æ –≤–æ—Ç –∫–æ–≥–¥–∞ –Ω–∞—Å—Ç–∞–ª —Å–µ–Ω—Ç—è–±—Ä—å –¥–µ–Ω—å–≥–∏ —Å–æ –∫—Ä —Å—á–µ—Ç–∞ –ø—Ä–æ–ø–∞–ª–∏ –∏ –Ω–∞ –∫—Ä–µ–¥–∏—Ç –Ω–µ —É—à–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –∑–≤–æ–Ω–∫–æ–≤ –≤ –±–∞–Ω–∫ –Ω–∏–∫—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ —Ä–µ—à–∏–ª –ø–æ–µ—Ö–∞–ª –≤ –±–∞–Ω–∫ —Ç–∞–º —Å–∫–∞–∑–∞–ª–∏ —á—Ç–æ –∫—Ç–æ —Ç–æ –ø–µ—Ä–µ–≤—ë–ª –¥–µ–Ω—å–≥–∏ –Ω–∞ –∫–∞–∫–æ–π —Ç–æ –≤–µ—Ä—Ç—É–∞–ª—å–Ω—ã–π —Å—á–µ—Ç –∏ –æ–Ω–∏ —Ç–µ–ø–µ—Ä—å –Ω–µ –ø—Ä–∏–∫–∞—Å–∞–µ–º—ã–µ —Ç–æ –µ—Å—Ç—å –Ω–∏–∫—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –∏–∑ –≤–µ—Ä–Ω—É—Ç—å –æ—Å—Ç–∞–≤–∏–ª –∑–∞—è–≤–∫—É —Å–∫–∞–∑–∞–ª–∏ –∂–¥–∞—Ç—å –∞–±–æ—á–∏—Ö –¥–Ω–µ–π –ø—Ä–æ—à–µ–ª –º–µ—Å—è—Ü –Ω–∏–∫—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ —Ä–µ—à–∏–ª –∏ –¥–∞–∂–µ –Ω–µ –ø–æ–∑–≤–æ–Ω–∏–ª–∏ –∞ —Ç–æ–ª—å–∫–æ —Å–º—Å –ø—Ä–∏—Å–ª–∞–ª–∏ —á—Ç–æ –º–æ–ª –∏–∑–≤–∏–Ω–∏—Ç–µ –≤–∞—à–µ –ø—Ä–æ–±–ª–µ–º–∞ —Ä–µ—à–∞–µ—Ç—Å—è –∏ –µ—â–µ –Ω–∞ 15 –¥–Ω–µ–π –≤–æ–æ–±—â–µ–º –ø—Ä–æ—à–ª–∏ —Ç—Ä–∏ –º–µ—Å—è—Ü–∞ –∏–¥–µ—Ç –ø—Ä–æ—Å—Ä–æ—á–∫–∞ –ø–æ –∫—Ä–µ–¥–∏—Ç—É –ø–æ—Ç–æ–º—É —á—Ç–æ —Ç—Ä–µ—Ç–∏–π —Ä–∞–∑ —è –ª–æ–∂–∏—Ç—å –Ω–µ —Å–æ–±–∏—Ä–∞—é—Å—å –∞ –±–∞–Ω–∫ –º–Ω–µ –∑–≤–æ–Ω–∏—Ç –∏ —ç—Ç–æ —Å–∞–º–æ–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –∫–∞–∫ –∏–¥—Ç–∏ –≤ —Å—É–¥ \"}, {\"id\": 6, \"text\": \"–ø–æ–º–µ–Ω—è–ª–∏ –∫–æ–¥–æ–≤–æ–µ —Å–ª–æ–≤–æ —Å –æ—à–∏–±–∫–æ–π –ø–æ—Å–ª–µ –æ—Ç–º–µ–Ω—ã –ø—Ä–∏—Å—Ç–∞–≤–æ–º –∞—Ä–µ—Å—Ç–∞ –∫–∞—Ä—Ç—ã –≤ —Ç–µ—á–µ–Ω–∏–µ –Ω–µ–¥–µ–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—è —Å–ø–∏—Å—ã–≤–∞–Ω–∏—è —Å –º–æ–µ–≥–æ —Å—á–µ—Ç–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–≤—è–∑–∞—Ç—å—Å—è —Å –æ—Ç–¥–µ–ª–æ–º –ø–æ —Å–Ω—è—Ç–∏—é –∞—Ä–µ—Å—Ç–∞ –ø—Ä–∏ —Ç–æ–º —á—Ç–æ –≤—ã—à–ª–∏ —Å—Ä–æ–∫–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –º–æ–µ–≥–æ –∑–∞—è–≤–ª–µ–Ω–∏—è —Å –ø—Ä–∏–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –æ —Å–Ω—è—Ç–∏–∏ –∞—Ä–µ—Å—Ç–∞ —Å–æ —Å—á–µ—Ç–æ–≤ –ø–æ–º–∏–º–æ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –æ—Ç–º–µ–Ω—ã —Ä–∞–Ω–µ–µ –ø—Ä–∏—Å—Ç–∞–≤–æ–º –ø–æ–ª–Ω—ã–π –±–∞—Ä–¥–∞–∫ –≤ –¥–µ–π—Å—Ç–≤–∏—è—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –±–∞–Ω–∫–∞ –≤ –≥ –æ–¥–∏–Ω—Ü–æ–≤–æ \"}, {\"id\": 7, \"text\": \"–ø–æ–¥–∫–ª—é—á–∏–ª –∫–∞—Ä—Ç—É –∫ –ø—Ä–æ–≥—Ä–∞–º–º–µ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ —ç—Ç–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ –∫–∞–∂–¥—ã–π –º–µ—Å—è—Ü –≤—ã–ø–ª–∞—á–∏–≤–∞—é—Ç—Å—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –∑–∞ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ —Å—É–º–º–∞ –ø–æ–∫—É–ø–æ–∫ –∑–∞ –º–µ—Å—è—Ü –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª–µ–µ 15 –≤–æ—Ç —É–∂–µ –≤—Ç–æ—Ä–æ–π –º–µ—Å—è—Ü –ø–æ–¥—Ä—è–¥ –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ —Ö–æ—Ç—è —Å—É–º–º–∞ –ø–æ–∫—É–ø–æ–∫ –≤ –∞–ø—Ä–µ–ª–µ –±—ã–ª–∞ –±–æ–ª–µ–µ 50 –≤ –º–∞–µ –±–æ–ª–µ–µ 20 –Ω–∞–ø–∏—Å–∞–ª –∑–∞—è–≤–ª–µ–Ω–∏–µ –≤ —Ñ–∏–ª–∏–∞–ª–µ —á—Ç–æ–± —Ä–∞–∑–æ–±—Ä–∞–ª–∏—Å—å –ø–æ–ª—É—á–∏–ª –æ—Ç–≤–µ—Ç –æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è —á—Ç–æ –Ω–µ –≤—Å–µ –ø–æ–∫—É–ø–∫–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —è –Ω–µ –∏–º–µ—é –≤ –≤–∏–¥—É –ø–µ—Ä–µ–≤–æ–¥—ã —Å–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö –∏ —Ç –¥ –∏–º–µ–Ω–Ω–æ –ø–æ–∫—É–ø–∫–∏ –æ–± —ç—Ç–æ–º –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª–∞—Ö –¥–∞–Ω–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ –Ω–æ –Ω–∞ –¥–µ–ª–µ –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑—É–µ—à—å—Å—è –∫–∞—Ä—Ç–æ–π –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫–∏–µ –ø–æ–∫—É–ø–∫–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –∞ –∫–∞–∫–∏–µ –Ω–µ—Ç –≤ –¥—Ä—É–≥–∏—Ö –±–∞–Ω–∫–∞—Ö –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ–∫—É–ø–æ–∫ —Ç–∞–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—ã—Å–≤–µ—á–∏–≤–∞–µ—Ç—Å—è –≤ –ª–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ –∑–¥–µ—Å—å –∂–µ –≤ –ª–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ –≤—ã—Å–≤–µ—á–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ–∫—É–ø–∫–∏ –∞ –∫–∞–∫–∏–µ –∏–∑ –Ω–∏—Ö –∏–¥—É—Ç –≤ –∑–∞—á–µ—Ç –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –∫–∞–∫ –≤–µ—Å—Ç–∏ —É—á–µ—Ç –ø–æ–∫—É–ø–æ–∫ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–≤–æ–Ω–∏—Ç—å –≤ –±–∞–Ω–∫ —ç—Ç–æ –æ—á–µ–Ω—å –Ω–µ—É–¥–æ–±–Ω–æ —Å–ª–æ–∂–Ω–æ –∏ –≥–ª—É–ø–æ –∫–æ—Ä–æ—á–µ —Å–µ—Ä–∞—è —Å—Ö–µ–º–∞ –≤—Ä–æ–¥–µ –≤—Å—ë –∑–∞–∫–æ–Ω–Ω–æ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –±–∞–Ω–∫–∞ –∞ –ø–æ —Ñ–∞–∫—Ç—É –±–∞–Ω–∫ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∫—É–ø–∫–∞—Ö –∏ —Ç–µ–º —Å–∞–º—ã–º —É–º—ã—à–ª–µ–Ω–Ω–æ –≤–≤–æ–¥–∏—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ –Ω–µ—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ –∞ –∫–æ–≥–¥–∞ –Ω–µ—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ –∏ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —ç—Ç–æ —É–∂–µ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –±–∞–Ω–∫–∞ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É —Å–∫–∞–∑–∞–ª —á—Ç–æ –Ω–∏—á–µ–º –ø–æ–º–æ—á—å –Ω–µ –º–æ–∂–µ—Ç —è –ø–æ–ø—Ä–æ—Å–∏–ª –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –º–Ω–µ —É–±—ã—Ç–æ–∫ –Ω–æ –º–Ω–µ –±—ã–ª–æ –æ—Ç–∫–∞–∑–∞–Ω–æ –Ω–µ –ø–æ–Ω–∏–º–∞—é –ø–æ—á–µ–º—É –º–Ω–µ –æ—Ç–∫–∞–∑–∞–ª–∏ –∫–æ–≥–¥–∞ –º–Ω–µ –∑–≤–æ–Ω—è—Ç –∏–∑ –±–∞–Ω–∫–∞ –∏ –Ω–∞–≤—è–∑—ã–≤–∞—é—Ç –∫–∞–∫—É—é –Ω–∏–±—É–¥—å –∫–∞—Ä—Ç—É –∏–ª–∏ –∫—Ä–µ–¥–∏—Ç —Ç–æ –≥–æ–≤–æ—Ä—è—Ç —á—Ç–æ —è –æ—á–µ–Ω—å –≤–∞–∂–Ω—ã–π –¥–ª—è –±–∞–Ω–∫–∞ –∫–ª–∏–µ–Ω—Ç –∏ —á—Ç–æ –±–∞–Ω–∫ –æ—á–µ–Ω—å —Ü–µ–Ω–∏—Ç –º–µ–Ω—è –∑–∞ —Ç–æ —á—Ç–æ —è –ø–æ–ª—å–∑—É—é—Å—å –µ–≥–æ —É—Å–ª—É–≥–∞–º–∏ –∏ —Ç –¥ –∞ –∫–æ–≥–¥–∞ —è –ø—Ä–æ—à—É –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –º–Ω–µ —É–±—ã—Ç–æ–∫ —Ç–æ –æ—Ç–∫–∞–∑—ã–≤–∞—é—Ç –ø–æ–ª—É—á–∞–µ—Ç—Å—è —á—Ç–æ —è —Å–æ–≤—Å–µ–º –Ω–µ –≤–∞–∂–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –±–∞–Ω–∫–∞ —á—Ç–æ –≤—Å–µ —Å–ª–æ–≤–∞ –ø—Ä–æ –≤–∞–∂–Ω–æ—Å—Ç—å –∏ —Ü–µ–Ω–Ω–æ—Å—Ç—å —ç—Ç–æ –æ–±–º–∞–Ω –¥–≤–∞ –º–µ—Å—è—Ü–∞ –º–æ–π –≤–∫–ª–∞–¥ –ª–µ–∂–∞–ª –≤ –±–∞–Ω–∫–µ –∏ —è –Ω–µ –ø–æ–ª—É—á–∏–ª –∑–∞ —ç—Ç–æ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —á—Ç–æ –±–∞–Ω–∫ –¥—É–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ —Å–≤–æ–µ–π –≤—ã–≥–æ–¥–µ –∏ –Ω–µ –¥—É–º–∞–µ—Ç –æ –∫–ª–∏–µ–Ω—Ç–∞—Ö –≤—ã–≥–æ–¥–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–π —ç—Ç–æ –Ω–µ–ø–æ—Ä—è–¥–æ—á–Ω–æ —è –¥—É–º–∞–ª —á—Ç–æ —ç—Ç–æ —Å–æ–ª–∏–¥–Ω—ã–π –±–∞–Ω–∫ –¥–æ–≤–µ—Ä–∏–ª –µ–º—É —Å–≤–æ–∏ —Å—Ä–µ–¥—Å—Ç–≤–∞ –∏ –æ—Ñ–æ—Ä–º–∏–ª –∑–∞—Ä–ø–ª–∞—Ç–Ω—É—é –∫–∞—Ä—Ç—É –≤ –∏—Ç–æ–≥–µ —Ç–∞–∫–æ–π –æ–±–º–∞–Ω —Ç–∞–∫ –æ–±–∏–¥–Ω–æ —è –æ—á–µ–Ω—å —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω –Ω–µ –ø–æ–Ω–∏–º–∞—é –ø–æ—á–µ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –±–∞–Ω–∫–∞ –æ—Ç–∫–∞–∑–∞–ª—Å—è –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –º–Ω–µ —É–±—ã—Ç–∫–∏ –≤–∏–¥–∏–º–æ –Ω–µ –¥–æ—Ä–æ–∂–∞—Ç –∫–ª–∏–µ–Ω—Ç–∞–º–∏ –ø—Ä–∏ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–∏ —Å–≤–æ–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –±–∞–Ω–∫ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω—É—é –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Ç–µ–º —Å–∞–º—ã–º –≤–≤–æ–¥–∏—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ —Å–æ–ª–∏–¥–Ω—ã–µ –±–∞–Ω–∫–∏ —Ç–∞–∫ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –∏ –∫–æ–≥–¥–∞ –≤–æ–∑–Ω–∏–∫–∞—é—Ç —Å–ø–æ—Ä–Ω—ã–µ –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏ —Å–æ–ª–∏–¥–Ω—ã–µ –±–∞–Ω–∫–∏ —Å—Ç–∞—Ä–∞—é—Ç—Å—è –∏—Ö —Ä–µ—à–∞—Ç—å –∞ –Ω–µ —Ä–∞–∑–±—Ä–∞—Å—ã–≤–∞—é—Ç—Å—è –∫–ª–∏–µ–Ω—Ç–∞–º–∏ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –Ω–µ —Ö—Ä–∞–Ω–∏—Ç–µ –∑–¥–µ—Å—å —Å–≤–æ–∏ —Å–±–µ—Ä–µ–∂–µ–Ω–∏—è –≤—Å–µ –¥–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –±—É–¥—É –≤—ã–≤–æ–¥–∏—Ç—å –≤ –¥—Ä—É–≥–æ–π –±–∞–Ω–∫ –æ—á–µ–Ω—å –∂–∞–ª—å \"}, {\"id\": 8, \"text\": \"–¥–µ–Ω—å–≥–∏ —Å–Ω–∏–º–∞—é—Ç—Å—è –ø–æ –ø–æ–≤–æ–¥—É –∏ –±–µ–∑ –¥–æ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–æ–∑–≤–æ–Ω–∏—Ç—å—Å—è —ç—Ç–æ –≤–æ–æ–±—â–µ —Ü–µ–ª—ã–π –∫–≤–µ—Å—Ç –≤ –æ—Ñ–∏—Å–∞—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞—é—Ç –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ –Ω–µ –º–æ–≥—É—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å –∑–∞ —á—Ç–æ –±—ã–ª–∏ —Å–Ω—è—Ç—ã –¥–µ–Ω—å–≥–∏ –∞ –µ—Å–ª–∏ –≤—Å—ë –∂–µ –∑–≤—ë–∑–¥—ã —Å–æ—à–ª–∏—Å—å –∏ —Ç—ã –¥–æ–∑–≤–æ–Ω–∏—à—å—Å—è –¥–æ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ç–æ –æ–Ω–∏ –¥–∞—é—Ç –æ–¥–Ω—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∞ –≤ –±–∞–Ω–∫–µ –¥–∞—é—Ç –¥—Ä—É–≥—É—é –≤–æ–æ–±—â–µ–º —ç—Ç–æ –µ—â—ë —Ç–∞ –∫–æ–Ω—Ç–æ—Ä–∞ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –¥–∞–∂–µ –±–ª–∏–∑–∫–æ –ø–æ–¥—Ö–æ–¥–∏—Ç—å –∫ —ç—Ç–æ–º—É –±–∞–Ω–∫—É —ç—Ç–æ –æ–¥–∏–Ω —Å–ø–ª–æ—à–Ω–æ–π –≥–µ–º–æ—Ä—Ä–æ–π –∏–∑–≤–∏–Ω–∏—Ç–µ –±–æ–ª–µ–µ –æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –±–∞–Ω–∫–∞ —è –µ—â—ë –Ω–µ –≤—Å—Ç—Ä–µ—á–∞–ª–∞ –ø—Ä–∏—á—ë–º –≤–æ –≤—Å–µ—Ö —Å–º—ã—Å–ª–∞—Ö —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞ \"}, {\"id\": 9, \"text\": \"–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ –æ–±—Ä–∞—Ç–∏–ª–∞—Å—å –≤ –≥–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫—Ä–µ–¥–∏—Ç–∞ 14 –∞–≤–≥—É—Å—Ç–∞ –ø–æ–¥–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–¥–ø–∏—Å–∞–ª–∞ –¥–æ–≥–æ–≤–æ—Ä –æ—Å—Ç–∞–ª–æ—Å—å –∂–¥–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è –±–∞–Ω–∫–∞ –∂–¥–∞–ª–∞ 5 —Å—É—Ç–æ–∫ 22 –∞–≤–≥—É—Å—Ç–∞ –ø–æ–∑–≤–æ–Ω–∏–ª–∞ –Ω–∞ –≥–æ—Ä—è—á—É—é –ª–∏–Ω–∏—é —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –≤ –∫–∞–∫–æ–º —Å—Ç–∞—Ç—É—Å–µ –∑–∞—è–≤–∫–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä —Å–∫–∞–∑–∞–ª —á—Ç–æ –∑–∞—è–≤–∫–∞ –∑–∞–∫—Ä—ã—Ç–∞ —Ç –∫ —è —Å–∞–º–∞ –æ—Ç–∫–∞–∑–∞–ª–∞—Å—å –æ—Ç –∫—Ä–µ–¥–∏—Ç–∞ —Ö–æ—Ç—è —è –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–ª–∞—Å—å –∫–∞–∫ —Ç–∞–∫–æ–µ –º–æ–≥–ª–æ –ø–æ–ª—É—á–∏—Ç—å—Å—è —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ –≤ –¥—Ä—É–≥–∏–µ –±–∞–Ω–∫–∏ —è –Ω–µ –æ–±—Ä–∞—â–∞–ª–∞—Å—å –¥–µ–Ω—å–≥–∏ –Ω—É–∂–Ω—ã –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∑—Ä—è –ø—Ä–æ–∂–¥–∞–ª–∞ –∏ —Å—Ç–æ–∏—Ç –ª–∏ –∂–¥–∞—Ç—å –∫–æ–≥–¥–∞ —Ä–µ—à–∏—Ç—å—Å—è —ç—Ç–∞ –ø—Ä–æ–±–ª–µ–º–∞ –∏–ª–∏ –ª—É—á—à–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –¥—Ä—É–≥–æ–π –±–∞–Ω–∫ \"}]}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "texts = df.sample(10)['text'].tolist()\n",
    "json.dumps({\n",
    "    'data': [{'id': i, 'text': text} for i, text in enumerate(texts)]\n",
    "}, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "836df0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('restructing',),\n",
       " ('Salary&PremiumCards', 'debitCards'),\n",
       " ('debitCards',),\n",
       " ('creditCards', 'creditCardsService', 'currencyExchange', 'earlyRepayment'),\n",
       " ('Salary&PremiumCards', 'debitCards', 'transactionErrors'),\n",
       " ('creditCards',),\n",
       " ('debitCards',),\n",
       " ('creditCards',),\n",
       " ('Salary&PremiumCards', 'debitCards', 'depositAccess', 'deposits'),\n",
       " ('debitCards',)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_labels(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2421e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), batch_size):\n\u001b[32m      5\u001b[39m     batch_texts = df.head(\u001b[32m10\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].iloc[i:i+batch_size].tolist()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     batch_preds = \u001b[43mpredict_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     all_preds.extend(batch_preds)\n\u001b[32m      9\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mpredicted_classes\u001b[39m\u001b[33m'\u001b[39m] = all_preds\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mpredict_labels\u001b[39m\u001b[34m(texts, threshold)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(texts, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      3\u001b[39m     texts = [texts]  \u001b[38;5;66;03m# –µ—Å–ª–∏ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m inputs = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     14\u001b[39m     outputs = model(**inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2911\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2909\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2910\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2911\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2912\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2913\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2999\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2994\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2995\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not match batch length of `text_pair`:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2996\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2997\u001b[39m         )\n\u001b[32m   2998\u001b[39m     batch_text_or_text_pairs = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[32m-> \u001b[39m\u001b[32m2999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3001\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3019\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3021\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encode_plus(\n\u001b[32m   3022\u001b[39m         text=text,\n\u001b[32m   3023\u001b[39m         text_pair=text_pair,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3041\u001b[39m         **kwargs,\n\u001b[32m   3042\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3200\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   3190\u001b[39m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[32m   3191\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m   3192\u001b[39m     padding=padding,\n\u001b[32m   3193\u001b[39m     truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3197\u001b[39m     **kwargs,\n\u001b[32m   3198\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3202\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3218\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_fast.py:586\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;66;03m# Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension\u001b[39;00m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# (we say ~ because the number of overflow varies with the example in the batch)\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;66;03m# To match each overflowing sample with the original sample in the batch\u001b[39;00m\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# we add an overflow_to_sample_mapping array (see below)\u001b[39;00m\n\u001b[32m    585\u001b[39m sanitized_tokens = {}\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokens_and_encodings\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m]:\n\u001b[32m    587\u001b[39m     stack = [e \u001b[38;5;28;01mfor\u001b[39;00m item, _ \u001b[38;5;129;01min\u001b[39;00m tokens_and_encodings \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m item[key]]\n\u001b[32m    588\u001b[39m     sanitized_tokens[key] = stack\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "all_preds = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['text'].iloc[i:i+batch_size].tolist()\n",
    "    batch_preds = predict_labels(batch_texts)\n",
    "    all_preds.extend(batch_preds)\n",
    "\n",
    "df['predicted_classes'] = all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f947d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36cff86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(50357)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predicted_classes'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d603974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/final_dataset/classification_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"–≠—Ç–æ—Ç —Ñ–∏–ª—å–º –±—ã–ª –ø—Ä–æ—Å—Ç–æ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—ã–π, —è –≤ –≤–æ—Å—Ç–æ—Ä–≥–µ!\"\n",
    "predicted = predict_labels(example_text)\n",
    "print(predicted)\n",
    "# –Ω–∞–ø—Ä–∏–º–µ—Ä -> ['positive', 'emotion_happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e4f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0354e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c245fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
