{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455ac03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/george/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa09bf",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a73795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/df_final_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602fd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['predicted_classes_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad12b80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>dateCreate</th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>source</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>review</th>\n",
       "      <th>predicted_classes_refined</th>\n",
       "      <th>final_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>992651</td>\n",
       "      <td>не выполняют условия акции</td>\n",
       "      <td>в апреле 2025 года я рекомендовала дебетовую к...</td>\n",
       "      <td>2025-08-29T23:30:38.746003Z</td>\n",
       "      <td>debitCards</td>\n",
       "      <td>Умная карта (Премиум)</td>\n",
       "      <td>sravni</td>\n",
       "      <td>в апреле года я рекомендовала дебетовую карту ...</td>\n",
       "      <td>не выполняют условия акции  в апреле года я ре...</td>\n",
       "      <td>[1, 3, 14, 15]</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>998360</td>\n",
       "      <td>жалоба на услугу газпром бонус премиум</td>\n",
       "      <td>купил услугу газпром бонус премиум за 2 цель б...</td>\n",
       "      <td>2025-09-15T09:38:13.34818Z</td>\n",
       "      <td>debitCards</td>\n",
       "      <td>Отсутствует</td>\n",
       "      <td>sravni</td>\n",
       "      <td>купил услугу газпром бонус премиум за цель был...</td>\n",
       "      <td>жалоба на услугу газпром бонус премиум  купил ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[debitCards]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>993744</td>\n",
       "      <td>банк не отвечает за слова своих сотрудников не...</td>\n",
       "      <td>хочу поделиться историей которая убила моё дов...</td>\n",
       "      <td>2025-09-02T23:21:16.507166Z</td>\n",
       "      <td>debitCards</td>\n",
       "      <td>Умная карта</td>\n",
       "      <td>sravni</td>\n",
       "      <td>хочу поделиться историей которая моё к газпром...</td>\n",
       "      <td>банк не отвечает за слова своих сотрудников не...</td>\n",
       "      <td>[1, 6, 15]</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id                                              title  \\\n",
       "0      0  992651                        не выполняют условия акции    \n",
       "1      1  998360            жалоба на услугу газпром бонус премиум    \n",
       "2      2  993744  банк не отвечает за слова своих сотрудников не...   \n",
       "\n",
       "                                                text  \\\n",
       "0  в апреле 2025 года я рекомендовала дебетовую к...   \n",
       "1  купил услугу газпром бонус премиум за 2 цель б...   \n",
       "2  хочу поделиться историей которая убила моё дов...   \n",
       "\n",
       "                    dateCreate     product            sub_product  source  \\\n",
       "0  2025-08-29T23:30:38.746003Z  debitCards  Умная карта (Премиум)  sravni   \n",
       "1   2025-09-15T09:38:13.34818Z  debitCards            Отсутствует  sravni   \n",
       "2  2025-09-02T23:21:16.507166Z  debitCards            Умная карта  sravni   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  в апреле года я рекомендовала дебетовую карту ...   \n",
       "1  купил услугу газпром бонус премиум за цель был...   \n",
       "2  хочу поделиться историей которая моё к газпром...   \n",
       "\n",
       "                                              review  \\\n",
       "0  не выполняют условия акции  в апреле года я ре...   \n",
       "1  жалоба на услугу газпром бонус премиум  купил ...   \n",
       "2  банк не отвечает за слова своих сотрудников не...   \n",
       "\n",
       "  predicted_classes_refined                                      final_classes  \n",
       "0            [1, 3, 14, 15]  [debitCards, cashbackPromo, notifications, ref...  \n",
       "1                        []                                       [debitCards]  \n",
       "2                [1, 6, 15]  [debitCards, cashbackPromo, earlyRepayment, re...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1652c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['index', 'text', 'final_classes']].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c071a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество классов: 23\n",
      "Примеры меток: ['Salary&PremiumCards' 'autocredits' 'cardAccess' 'cashbackPromo'\n",
      " 'creditCards' 'creditCardsService' 'credits' 'currencyExchange'\n",
      " 'debitCards' 'depositAccess' 'deposits' 'earlyRepayment' 'loanIssues'\n",
      " 'mortgage' 'mortgageIssues' 'notifications' 'other' 'refinancing'\n",
      " 'remoteService' 'restructing' 'savings' 'serviceLevel'\n",
      " 'transactionErrors']\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['final_classes'])\n",
    "\n",
    "df['labels'] = y.tolist()\n",
    "\n",
    "print(\"Количество классов:\", len(mlb.classes_))\n",
    "print(\"Примеры меток:\", mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215ec15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'], df['labels'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_df = pd.DataFrame({'text': train_texts, 'labels': train_labels})\n",
    "test_df = pd.DataFrame({'text': test_texts, 'labels': test_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83141580",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e7cb4",
   "metadata": {},
   "source": [
    "## Classic Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a57ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#MODEL_NAME = \"DeepPavlov/rubert-base-cased\"\n",
    "# MODEL_NAME = \"DeepPavlov/rubert-base\"\n",
    "MODEL_NAME = \"ai-forever/ruBert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7a56d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341ae06d9ee44b83aa19506360ce5b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8379df9831147cba8459ee2e6758fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"__index_level_0__\"]) if \"__index_level_0__\" in train_dataset.column_names else train_dataset.remove_columns([\"text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"__index_level_0__\"]) if \"__index_level_0__\" in test_dataset.column_names else test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e63a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f9a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = (torch.sigmoid(torch.tensor(logits)) > 0.5).int().numpy()\n",
    "    labels = labels\n",
    "    return {\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53375cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d3dc783f2f4277afaeb5f2ae98200e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fc349d4a3e4d21a74fc5481e3603f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cast_labels_to_float(example):\n",
    "    example[\"labels\"] = [float(x) for x in example[\"labels\"]]\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(cast_labels_to_float)\n",
    "test_dataset = test_dataset.map(cast_labels_to_float)\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"../classifier_results\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='../logs',\n",
    "#     logging_steps=50,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"f1_micro\",\n",
    "#     save_total_limit=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369ba953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../classifier_results\",\n",
    "    evaluation_strategy=\"epoch\",       # оценка раз в эпоху\n",
    "    save_strategy=\"epoch\",             # сохраняем модель раз в эпоху\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,               # максимум 10 эпох\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='../logs',\n",
    "    logging_strategy=\"epoch\",          # логируем раз в эпоху\n",
    "    load_best_model_at_end=True,       # возвращаем лучшую модель\n",
    "    metric_for_best_model=\"f1_micro\",  # метрика для ранней остановки\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "# callback для ранней остановки\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=1)  \n",
    "# patience=1 → если следующая эпоха не улучшила метрику, останавливаемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ed6166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8167b6d69f874e70b67b554284b949ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_307491/492247788.py:1: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  train_dataset = train_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd20a47d7074ff9a8665b5ffad7b63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_307491/492247788.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  test_dataset  = test_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n",
    "test_dataset  = test_dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n",
    "\n",
    "# Убираем оригинальные labels (чтобы Trainer не трогал их)\n",
    "train_dataset = train_dataset.remove_columns(\"labels\")\n",
    "test_dataset  = test_dataset.remove_columns(\"labels\")\n",
    "\n",
    "# Переименовываем float колонку в labels\n",
    "train_dataset = train_dataset.rename_column(\"labels_float\", \"labels\")\n",
    "test_dataset  = test_dataset.rename_column(\"labels_float\", \"labels\")\n",
    "\n",
    "# Теперь set_format\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7080ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Проверяем, есть ли GPU\n",
    "print(torch.cuda.is_available())  # True, если GPU доступен\n",
    "print(torch.cuda.device_count())  # количество доступных GPU\n",
    "print(torch.cuda.get_device_name(0))  # имя первого GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46f435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20144' max='20144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20144/20144 44:48, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.726126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.108131</td>\n",
       "      <td>0.769384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.106506</td>\n",
       "      <td>0.777725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.105078</td>\n",
       "      <td>0.781371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20144, training_loss=0.10831447325593617, metrics={'train_runtime': 2689.3523, 'train_samples_per_second': 59.918, 'train_steps_per_second': 7.49, 'total_flos': 2.120285478614016e+16, 'train_loss': 0.10831447325593617, 'epoch': 4.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5876f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Классификационный отчёт ---\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Salary&PremiumCards       0.79      0.73      0.76       892\n",
      "        autocredits       0.78      0.68      0.72       788\n",
      "         cardAccess       0.80      0.79      0.80       900\n",
      "      cashbackPromo       0.83      0.91      0.87      1064\n",
      "        creditCards       0.78      0.68      0.73      1669\n",
      " creditCardsService       0.79      0.72      0.75       856\n",
      "            credits       0.79      0.71      0.75       814\n",
      "   currencyExchange       0.77      0.44      0.56       557\n",
      "         debitCards       0.86      0.87      0.87      5686\n",
      "      depositAccess       0.79      0.65      0.71       626\n",
      "           deposits       0.75      0.76      0.75       715\n",
      "     earlyRepayment       0.83      0.83      0.83       906\n",
      "         loanIssues       0.82      0.71      0.76       688\n",
      "           mortgage       0.79      0.80      0.79       674\n",
      "     mortgageIssues       0.84      0.85      0.84       787\n",
      "      notifications       0.78      0.71      0.74       826\n",
      "              other       0.00      0.00      0.00        97\n",
      "        refinancing       0.75      0.74      0.75       686\n",
      "      remoteService       0.72      0.68      0.70       799\n",
      "        restructing       0.60      0.41      0.48       217\n",
      "            savings       0.70      0.55      0.61       563\n",
      "       serviceLevel       0.67      0.01      0.03       146\n",
      "  transactionErrors       0.82      0.77      0.79       735\n",
      "\n",
      "          micro avg       0.81      0.76      0.78     21691\n",
      "          macro avg       0.74      0.65      0.68     21691\n",
      "       weighted avg       0.80      0.76      0.77     21691\n",
      "        samples avg       0.77      0.75      0.75     21691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "preds = (torch.sigmoid(torch.tensor(predictions.predictions)) > 0.5).int().numpy()\n",
    "\n",
    "print(\"\\n--- Классификационный отчёт ---\\n\")\n",
    "print(classification_report(test_labels.tolist(), preds, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa945f",
   "metadata": {},
   "source": [
    "## Final Model (Full Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bda2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>final_classes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>в апреле 2025 года я рекомендовала дебетовую к...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>купил услугу газпром бонус премиум за 2 цель б...</td>\n",
       "      <td>[debitCards]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>хочу поделиться историей которая убила моё дов...</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>в июне 2025 года я порекомендовал премиальную ...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>добрый день в связи с устройством на новую раб...</td>\n",
       "      <td>[debitCards, depositAccess, remoteService]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50352</th>\n",
       "      <td>50352</td>\n",
       "      <td>газпромбанк тут заманивал кредитом одобренным ...</td>\n",
       "      <td>[other, earlyRepayment, loanIssues]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50353</th>\n",
       "      <td>50353</td>\n",
       "      <td>ситуация довольно странная для входа в интерне...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50354</th>\n",
       "      <td>50354</td>\n",
       "      <td>в банке нравится все и обслуживание на отлично...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>50355</td>\n",
       "      <td>обращение в контакт центр 10 баллов а вот рабо...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50356</th>\n",
       "      <td>50356</td>\n",
       "      <td>открывала счет с ежедневным начислением процен...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50357 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  \\\n",
       "0          0  в апреле 2025 года я рекомендовала дебетовую к...   \n",
       "1          1  купил услугу газпром бонус премиум за 2 цель б...   \n",
       "2          2  хочу поделиться историей которая убила моё дов...   \n",
       "3          3  в июне 2025 года я порекомендовал премиальную ...   \n",
       "4          4  добрый день в связи с устройством на новую раб...   \n",
       "...      ...                                                ...   \n",
       "50352  50352  газпромбанк тут заманивал кредитом одобренным ...   \n",
       "50353  50353  ситуация довольно странная для входа в интерне...   \n",
       "50354  50354  в банке нравится все и обслуживание на отлично...   \n",
       "50355  50355  обращение в контакт центр 10 баллов а вот рабо...   \n",
       "50356  50356  открывала счет с ежедневным начислением процен...   \n",
       "\n",
       "                                           final_classes  \\\n",
       "0      [debitCards, cashbackPromo, notifications, ref...   \n",
       "1                                           [debitCards]   \n",
       "2      [debitCards, cashbackPromo, earlyRepayment, re...   \n",
       "3      [debitCards, cashbackPromo, notifications, ref...   \n",
       "4             [debitCards, depositAccess, remoteService]   \n",
       "...                                                  ...   \n",
       "50352                [other, earlyRepayment, loanIssues]   \n",
       "50353                                            [other]   \n",
       "50354                                            [other]   \n",
       "50355                                            [other]   \n",
       "50356                                            [other]   \n",
       "\n",
       "                                                  labels  \n",
       "0      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "50352  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "50353  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50354  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50355  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50356  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[50357 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d67fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ff92c3088841b5843bb8917c5851d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c8f97eb2904867b0e0ba15e2908907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "dataset = dataset.map(lambda x: {\"labels_float\": np.array(x[\"labels\"], dtype=np.float32)})\n",
    "dataset = dataset.remove_columns(\"labels\")\n",
    "dataset = dataset.rename_column(\"labels_float\", \"labels\")\n",
    "dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2193accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6567dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gleb/LCT_2025/.venv/lib/python3.13/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../classifier_full_model\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,           # только 4 эпохи\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='../logs_full',\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,  # без early stopping\n",
    "    save_total_limit=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b6409d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25180' max='25180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25180/25180 57:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6295</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12590</td>\n",
       "      <td>0.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18885</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25180</td>\n",
       "      <td>0.056900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25180, training_loss=0.07849992141541837, metrics={'train_runtime': 3477.2388, 'train_samples_per_second': 57.928, 'train_steps_per_second': 7.241, 'total_flos': 2.650396322367283e+16, 'train_loss': 0.07849992141541837, 'epoch': 4.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# обучение\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f8109cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../classifier_full_model/tokenizer_config.json',\n",
       " '../classifier_full_model/special_tokens_map.json',\n",
       " '../classifier_full_model/vocab.txt',\n",
       " '../classifier_full_model/added_tokens.json',\n",
       " '../classifier_full_model/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../classifier_full_model\")\n",
    "tokenizer.save_pretrained(\"../classifier_full_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0da5b9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>final_classes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>в апреле 2025 года я рекомендовала дебетовую к...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>купил услугу газпром бонус премиум за 2 цель б...</td>\n",
       "      <td>[debitCards]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>хочу поделиться историей которая убила моё дов...</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>в июне 2025 года я порекомендовал премиальную ...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>добрый день в связи с устройством на новую раб...</td>\n",
       "      <td>[debitCards, depositAccess, remoteService]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50352</th>\n",
       "      <td>газпромбанк тут заманивал кредитом одобренным ...</td>\n",
       "      <td>[other, earlyRepayment, loanIssues]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50353</th>\n",
       "      <td>ситуация довольно странная для входа в интерне...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50354</th>\n",
       "      <td>в банке нравится все и обслуживание на отлично...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>обращение в контакт центр 10 баллов а вот рабо...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50356</th>\n",
       "      <td>открывала счет с ежедневным начислением процен...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50357 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      в апреле 2025 года я рекомендовала дебетовую к...   \n",
       "1      купил услугу газпром бонус премиум за 2 цель б...   \n",
       "2      хочу поделиться историей которая убила моё дов...   \n",
       "3      в июне 2025 года я порекомендовал премиальную ...   \n",
       "4      добрый день в связи с устройством на новую раб...   \n",
       "...                                                  ...   \n",
       "50352  газпромбанк тут заманивал кредитом одобренным ...   \n",
       "50353  ситуация довольно странная для входа в интерне...   \n",
       "50354  в банке нравится все и обслуживание на отлично...   \n",
       "50355  обращение в контакт центр 10 баллов а вот рабо...   \n",
       "50356  открывала счет с ежедневным начислением процен...   \n",
       "\n",
       "                                           final_classes  \\\n",
       "0      [debitCards, cashbackPromo, notifications, ref...   \n",
       "1                                           [debitCards]   \n",
       "2      [debitCards, cashbackPromo, earlyRepayment, re...   \n",
       "3      [debitCards, cashbackPromo, notifications, ref...   \n",
       "4             [debitCards, depositAccess, remoteService]   \n",
       "...                                                  ...   \n",
       "50352                [other, earlyRepayment, loanIssues]   \n",
       "50353                                            [other]   \n",
       "50354                                            [other]   \n",
       "50355                                            [other]   \n",
       "50356                                            [other]   \n",
       "\n",
       "                                                  labels  \n",
       "0      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "50352  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "50353  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50354  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50355  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50356  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[50357 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d2e80",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfd8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../classifier_full_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67724d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "model.eval()\n",
    "\n",
    "# если доступен GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bd6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(texts, threshold=0.5):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]  # если один текст\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    # бинаризация по порогу\n",
    "    preds = (probs > threshold).astype(int)\n",
    "\n",
    "    # преобразуем обратно в имена меток\n",
    "    predicted_labels = [mlb.inverse_transform([p])[0] for p in preds]\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2623ca1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Salary&PremiumCards', 'autocredits', 'cardAccess',\n",
       "       'cashbackPromo', 'creditCards', 'creditCardsService', 'credits',\n",
       "       'currencyExchange', 'debitCards', 'depositAccess', 'deposits',\n",
       "       'earlyRepayment', 'loanIssues', 'mortgage', 'mortgageIssues',\n",
       "       'notifications', 'other', 'refinancing', 'remoteService',\n",
       "       'restructing', 'savings', 'serviceLevel', 'transactionErrors'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32b12e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{MODEL_PATH}/final_mlb_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(mlb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b49ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{MODEL_PATH}/final_mlb_encoder.pkl', 'rb') as f:\n",
    "    mlb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1952f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>final_classes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>в апреле 2025 года я рекомендовала дебетовую к...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>купил услугу газпром бонус премиум за 2 цель б...</td>\n",
       "      <td>[debitCards]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>хочу поделиться историей которая убила моё дов...</td>\n",
       "      <td>[debitCards, cashbackPromo, earlyRepayment, re...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>в июне 2025 года я порекомендовал премиальную ...</td>\n",
       "      <td>[debitCards, cashbackPromo, notifications, ref...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>добрый день в связи с устройством на новую раб...</td>\n",
       "      <td>[debitCards, depositAccess, remoteService]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50352</th>\n",
       "      <td>50352</td>\n",
       "      <td>газпромбанк тут заманивал кредитом одобренным ...</td>\n",
       "      <td>[other, earlyRepayment, loanIssues]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50353</th>\n",
       "      <td>50353</td>\n",
       "      <td>ситуация довольно странная для входа в интерне...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50354</th>\n",
       "      <td>50354</td>\n",
       "      <td>в банке нравится все и обслуживание на отлично...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>50355</td>\n",
       "      <td>обращение в контакт центр 10 баллов а вот рабо...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50356</th>\n",
       "      <td>50356</td>\n",
       "      <td>открывала счет с ежедневным начислением процен...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50357 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  \\\n",
       "0          0  в апреле 2025 года я рекомендовала дебетовую к...   \n",
       "1          1  купил услугу газпром бонус премиум за 2 цель б...   \n",
       "2          2  хочу поделиться историей которая убила моё дов...   \n",
       "3          3  в июне 2025 года я порекомендовал премиальную ...   \n",
       "4          4  добрый день в связи с устройством на новую раб...   \n",
       "...      ...                                                ...   \n",
       "50352  50352  газпромбанк тут заманивал кредитом одобренным ...   \n",
       "50353  50353  ситуация довольно странная для входа в интерне...   \n",
       "50354  50354  в банке нравится все и обслуживание на отлично...   \n",
       "50355  50355  обращение в контакт центр 10 баллов а вот рабо...   \n",
       "50356  50356  открывала счет с ежедневным начислением процен...   \n",
       "\n",
       "                                           final_classes  \\\n",
       "0      [debitCards, cashbackPromo, notifications, ref...   \n",
       "1                                           [debitCards]   \n",
       "2      [debitCards, cashbackPromo, earlyRepayment, re...   \n",
       "3      [debitCards, cashbackPromo, notifications, ref...   \n",
       "4             [debitCards, depositAccess, remoteService]   \n",
       "...                                                  ...   \n",
       "50352                [other, earlyRepayment, loanIssues]   \n",
       "50353                                            [other]   \n",
       "50354                                            [other]   \n",
       "50355                                            [other]   \n",
       "50356                                            [other]   \n",
       "\n",
       "                                                  labels  \n",
       "0      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "50352  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "50353  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50354  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50355  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "50356  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[50357 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebfe3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(texts, threshold=0.5):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]  # если один текст\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    # бинаризация по порогу\n",
    "    preds = (probs > threshold).astype(int)\n",
    "    \n",
    "    # теперь preds точно numpy array с формой (num_texts, num_labels)\n",
    "    predicted_labels = mlb.inverse_transform(preds)\n",
    "    \n",
    "    return list(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d543929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3]\n",
    "l.pop(0)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2ebd378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": [{\"id\": 0, \"text\": \"я брал кредит уже выплатил пользуюсь картами банка у меня нет никаких нареканий по поводу работы и обслуживания мне очень нравится работа банка хочется пожелать всем работникам газпромбанка здоровья и успехов \"}, {\"id\": 1, \"text\": \"недавно обратился в газпромбанк и был ужасно удивлён разгильдяйским отношением банка к клиенту br 22 07 оставил заявку на кредитную карту банк одобрил заявку на кредитную карту на следующий день со мной связался сотрудник банка с которым мы проверили данные и согласовали время для приезда курьера 24 07 ко мне приехал курьер для подписания договора на кредитную карту но кто то в офисе перепутал вложения и в конверте с моим именем оказался договор на совершенно другого человека мы с курьером договорились что он привезёт мой договор через день согласовали время и спокойно попрощались как вечером этого же дня мне поступает смс от газпром банка что по моей заявке принято отрицательное решение сказать что я удивился ничего не сказать я тут же позвонил на горячую линию где мне сказали что это было предварительно одобренное решение на что я ответил что мне пришла смс о том что мне одобрена карта с лимитом а также если бы в офисе кто то не перепутал конверты то я бы подписал с банком договор на кредитную карту тут оператор начала рассказывать о том что банк мог все равно мог бы отказать мне в кредитной карте на мой вопрос как бы банк смог бы разорвать кредитный договор спустя нескольких часов после подписание оператор ответить не смогла br обращаться или не обращаться в этот банк за кредитными картами думайте сами \"}, {\"id\": 2, \"text\": \"одолжил на три дня и вернул а спустя пару дней списали ещё это что нормально что ли гигантский процент условия на столько не понятно написано что пока разберёшься короче отказываюсь от таких услуг и всем очень не советую связываться с подобным качают газ из недр нашей общей земли продают да ещё и людей обманывают \"}, {\"id\": 3, \"text\": \"интернет банк показывает неправильный по счету техотдел целый месяц занимается констатацией этого факта звонками на мобилу в последний звонок сказали вам колл центр посчитает начисленные деньги по счету звоню в колл центр там говорят мы не знаем как производится расчет приходите в офис два года назад попросил чтобы показывали не только название но и номер счета куда уходят деньги за жкх так и не делали \"}, {\"id\": 4, \"text\": \"14 03 2023 у меня закончилась процедура реализации имущества и я была освобождена от долгов по решению арбитражного суда после получения решения часть банков автоматически закрыли долги в часть я отнесла решение суда однако газпромбанк долг закрывать не собирается когда я 13 07 2023 пришла в отделение по адресу химкинский бульвар д 23 у меня отказались принять решение суда и куда либо его отправить сказали ехать в центральный офис в канцелярию хотя на горячей линии сказали потом что посещение центрального офиса невозможно и самое главное сотрудник отделения задала мне следующий вопрос когда собираетесь оплачивать долг и обслуживание по кредитной карте тем самым считай потребовав у меня погасить долг зная что я являюсь банкротом и освобождена от долга когда после всего этого я созвонилась с юристом чтобы уточнить у него что в этом случае делать она сидела и хихикала со своей коллегой смотря на мой разговор что сотрудники себе позволяют и когда будет списан мой долг \"}, {\"id\": 5, \"text\": \"с банком знаком давно было все нормально до августа 2022 год в августе пошел в отпуск и решил положить на кредит за два месяца за август вычли но вот когда настал сентябрь деньги со кр счета пропали и на кредит не ушли после всех звонков в банк никто ничего не решил поехал в банк там сказали что кто то перевёл деньги на какой то вертуальный счет и они теперь не прикасаемые то есть никто не может из вернуть оставил заявку сказали ждать абочих дней прошел месяц никто ничего не решил и даже не позвонили а только смс прислали что мол извините ваше проблема решается и еще на 15 дней вообщем прошли три месяца идет просрочка по кредиту потому что третий раз я ложить не собираюсь а банк мне звонит и это самое предлагает ничего не останется как идти в суд \"}, {\"id\": 6, \"text\": \"поменяли кодовое слово с ошибкой после отмены приставом ареста карты в течение недели продолжаются списывания с моего счета невозможно связаться с отделом по снятию ареста при том что вышли сроки рассмотрения моего заявления с приложенными документами о снятии ареста со счетов помимо электронной отмены ранее приставом полный бардак в действиях сотрудников банка в г одинцово \"}, {\"id\": 7, \"text\": \"подключил карту к программе лояльности процент по этой программе каждый месяц выплачиваются вознаграждения за накопительный вклад сумма покупок за месяц должна быть более 15 вот уже второй месяц подряд не приходит вознаграждение хотя сумма покупок в апреле была более 50 в мае более 20 написал заявление в филиале чтоб разобрались получил ответ оказывается что не все покупки учитываются я не имею в виду переводы снятие наличных и т д именно покупки об этом говорится в правилах данной программы лояльности но на деле когда пользуешься картой очень сложно определить какие покупки учитываются а какие нет в других банках если есть категории покупок такая информация высвечивается в личном кабинете здесь же в личном кабинете высвечиваются только покупки а какие из них идут в зачет непонятно возникает вопрос как вести учет покупок после каждой операции звонить в банк это очень неудобно сложно и глупо короче серая схема вроде всё законно со стороны банка а по факту банк не предоставляет полную информацию о покупках и тем самым умышленно вводит клиентов в заблуждение нет прозрачности а когда нет прозрачности и адекватной информации это уже мошенничество представитель банка по телефону сказал что ничем помочь не может я попросил компенсировать мне убыток но мне было отказано не понимаю почему мне отказали когда мне звонят из банка и навязывают какую нибудь карту или кредит то говорят что я очень важный для банка клиент и что банк очень ценит меня за то что я пользуюсь его услугами и т д а когда я прошу компенсировать мне убыток то отказывают получается что я совсем не важный клиент для банка что все слова про важность и ценность это обман два месяца мой вклад лежал в банке и я не получил за это вознаграждение получается что банк думает только о своей выгоде и не думает о клиентах выгода не может быть односторонней это непорядочно я думал что это солидный банк доверил ему свои средства и оформил зарплатную карту в итоге такой обман так обидно я очень разочарован не понимаю почему представитель банка отказался компенсировать мне убытки видимо не дорожат клиентами при продвижении своих продуктов банк не предоставляет полную и прозрачную информацию тем самым вводит клиентов в заблуждение солидные банки так не работают и когда возникают спорные или проблемные ситуации солидные банки стараются их решать а не разбрасываются клиентами не рекомендую не храните здесь свои сбережения все денежные средства буду выводить в другой банк очень жаль \"}, {\"id\": 8, \"text\": \"деньги снимаются по поводу и без до поддержки дозвониться это вообще целый квест в офисах сотрудники ничего не знают каждый вопрос это проблема не могут ответить за что были сняты деньги а если всё же звёзды сошлись и ты дозвонишься до поддержки то они дают одну информацию а в банке дают другую вообщем это ещё та контора не рекомендую даже близко подходить к этому банку это один сплошной геморрой извините более отвратительного банка я ещё не встречала причём во всех смыслах этого слова \"}, {\"id\": 9, \"text\": \"здравствуйте обратилась в газпромбанк для получения потребительского кредита 14 августа подала необходимые документы подписала договор осталось ждать решения банка ждала 5 суток 22 августа позвонила на горячую линию чтобы узнать в каком статусе заявка оператор сказал что заявка закрыта т к я сама отказалась от кредита хотя я не отказывалась как такое могло получиться что делать дальше в другие банки я не обращалась деньги нужны получается зря прождала и стоит ли ждать когда решиться эта проблема или лучше обратиться в другой банк \"}]}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "texts = df.sample(10)['text'].tolist()\n",
    "json.dumps({\n",
    "    'data': [{'id': i, 'text': text} for i, text in enumerate(texts)]\n",
    "}, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "836df0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('restructing',),\n",
       " ('Salary&PremiumCards', 'debitCards'),\n",
       " ('debitCards',),\n",
       " ('creditCards', 'creditCardsService', 'currencyExchange', 'earlyRepayment'),\n",
       " ('Salary&PremiumCards', 'debitCards', 'transactionErrors'),\n",
       " ('creditCards',),\n",
       " ('debitCards',),\n",
       " ('creditCards',),\n",
       " ('Salary&PremiumCards', 'debitCards', 'depositAccess', 'deposits'),\n",
       " ('debitCards',)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_labels(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2421e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), batch_size):\n\u001b[32m      5\u001b[39m     batch_texts = df.head(\u001b[32m10\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].iloc[i:i+batch_size].tolist()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     batch_preds = \u001b[43mpredict_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     all_preds.extend(batch_preds)\n\u001b[32m      9\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mpredicted_classes\u001b[39m\u001b[33m'\u001b[39m] = all_preds\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mpredict_labels\u001b[39m\u001b[34m(texts, threshold)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(texts, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      3\u001b[39m     texts = [texts]  \u001b[38;5;66;03m# если один текст\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m inputs = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     14\u001b[39m     outputs = model(**inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2911\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2909\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2910\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2911\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2912\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2913\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2999\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2994\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2995\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not match batch length of `text_pair`:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2996\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2997\u001b[39m         )\n\u001b[32m   2998\u001b[39m     batch_text_or_text_pairs = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[32m-> \u001b[39m\u001b[32m2999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3001\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3019\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3021\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encode_plus(\n\u001b[32m   3022\u001b[39m         text=text,\n\u001b[32m   3023\u001b[39m         text_pair=text_pair,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3041\u001b[39m         **kwargs,\n\u001b[32m   3042\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3200\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   3190\u001b[39m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[32m   3191\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m   3192\u001b[39m     padding=padding,\n\u001b[32m   3193\u001b[39m     truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3197\u001b[39m     **kwargs,\n\u001b[32m   3198\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3202\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3218\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/LCT_2025/.venv/lib/python3.13/site-packages/transformers/tokenization_utils_fast.py:586\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;66;03m# Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension\u001b[39;00m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# (we say ~ because the number of overflow varies with the example in the batch)\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;66;03m# To match each overflowing sample with the original sample in the batch\u001b[39;00m\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# we add an overflow_to_sample_mapping array (see below)\u001b[39;00m\n\u001b[32m    585\u001b[39m sanitized_tokens = {}\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokens_and_encodings\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m]:\n\u001b[32m    587\u001b[39m     stack = [e \u001b[38;5;28;01mfor\u001b[39;00m item, _ \u001b[38;5;129;01min\u001b[39;00m tokens_and_encodings \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m item[key]]\n\u001b[32m    588\u001b[39m     sanitized_tokens[key] = stack\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "all_preds = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df['text'].iloc[i:i+batch_size].tolist()\n",
    "    batch_preds = predict_labels(batch_texts)\n",
    "    all_preds.extend(batch_preds)\n",
    "\n",
    "df['predicted_classes'] = all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f947d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36cff86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(50357)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predicted_classes'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d603974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/final_dataset/classification_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Этот фильм был просто невероятный, я в восторге!\"\n",
    "predicted = predict_labels(example_text)\n",
    "print(predicted)\n",
    "# например -> ['positive', 'emotion_happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e4f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0354e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c245fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
